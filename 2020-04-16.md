# 16 April 2020

## NextTrace

Questions and observations for our survey-based digital contract tracing
implementation:

 1. What's the time lag between people testing positive and PH learning of the
    new case?  This is the delay "baked in" to any attempts to isolate of the
    case's exposed contacts if PH submits cases to NextTrace.  Too long and it
    would impact the efficacy of NextTrace, but we can't control it directly.

 2. Relatedly, do we need to short-circuit PH-reported cases which tested
    positive too long ago, i.e. where _current date_ − _test date_ > _X_ days?

 3. If a case contact develops symptoms, becomes a presumptive case themselves,
    completes our case survey, and then later is also reported as a confirmed
    case, we likely need to associate those records, e.g. to avoid a person
    getting two invites.  Similarly, we will likely want to handle an
    individual being exposed to more than one case in a short-period of time.

    Two possible approaches to maintaining an association:

     a. match by PII; won't be flawless, but if PII is carefully chosen and
        normalized then can probably be pretty good.

     b. match by unique code; challenge is successfully passing the code
        through the initial exposure alert → {symptom monitoring → presumptive
        case report, testing → confirmed case report}.

    Only (a) really seems practical to me and can use phone numbers and email
    addresses.

 4. Relatedly, we probably want some overall rate-limiting on how often an
    individual can be a reported case and fill out the case survey.

 5. Where is validation of the single-use, non-spoofable invites to the case
    survey happening?
 
    Two possible approaches:
    
     a. The frontend talks to the backend or survey host to validate based on a
        code in the invite link.
      
     b. The backend creates a blank/minimally-filled case survey response based
        on the initial case report and embeds a non-guessable id for that
        response in the invite link, which the frontend passes thru to the
        survey host.

 6. Relying on trusted partners to report confirmed cases means we avoid having
    to verify those.  However, there seems to be no way we could possibly
    verify that a presumptive case has the symptoms they say they do before
    acting on it.  Someone who wanted to spoof the system would have to 

 7. It seems we'll want a single authenticated case reporting REST API for:

    - Manual reporting frontend for our partners (public health, testing labs?, employers?)
    - Automatic reporting by the same
    - Automatic reporting by symptom trackers (our own or third-party)

    Decisions are necessary about the minimum set of information collected, but
    it likely includes:
    
    - Name
    - Phone numbers
    - Email addresses
    - Confirmed vs. Presumptive
    - "Detection" date: test date (confirmed) or symptom onset date
      (presumptive)
    - ZIP code?

    This API (or a related one) could return the case's survey invite details.

 8. It'd be good to use the delivery status reports from Twilio/Sendgrid/… to
    track which text/email case survey invites, exposure alerts, symptom
    check-ins, etc. aren't making it.  Probably a batch cronjob (pull) or
    another webhook receiver (push), if the messaging API offers the latter.

 9. What data do we delete if a case declines the case survey?  If a case
    contact declines symptom monitoring?  If the case survey/symptom monitoring
    invite is passively declined by expiring after X days?
